In [1]:
from nltk.tokenize import sent_tokenize, word_tokenize
text1="Hey, Kamal, how are you? I heard you are trying to get out of your comfort zone and that's awesome "
print(sent_tokenize(text1))
print(word_tokenize(text1))
['Hey, Kamal, how are you?', "I heard you are trying to get out of your comfort zone and that's awesome"]
['Hey', ',', 'Kamal', ',', 'how', 'are', 'you', '?', 'I', 'heard', 'you', 'are', 'trying', 'to', 'get', 'out', 'of', 'your', 'comfort', 'zone', 'and', 'that', "'s", 'awesome']
In [2]:
for i in word_tokenize(text1):
    print(i)
Hey
,
Kamal
,
how
are
you
?
I
heard
you
are
trying
to
get
out
of
your
comfort
zone
and
that
's
awesome
In [3]:
for i in sent_tokenize(text1):
    print(i)
Hey, Kamal, how are you?
I heard you are trying to get out of your comfort zone and that's awesome
In [ ]:
